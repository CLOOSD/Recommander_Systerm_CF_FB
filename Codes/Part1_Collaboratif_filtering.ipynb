{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nettoyage des données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(9001)\n",
    "#pour avoir toujours les memes erreurs à chaque fois qu'on re exécute le projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tab = pd.read_csv('ratings.csv')\n",
    "#tab = pd.read_csv('ratings_new.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'userId', u'movieId', u'rating', u'timestamp'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le nombre des utilisateurs est :671 Et le nombre des items est: 9066\n"
     ]
    }
   ],
   "source": [
    "useri,frequsers=np.unique(tab.userId,return_counts=True)#useri les id des users, frequsers les freq de chaque user\n",
    "itemi,freqitems=np.unique(tab.movieId,return_counts=True)#itemi les id des item, freqitem les freq de chaque item\n",
    "n_users=len(useri)\n",
    "n_items=len(itemi)\n",
    "print(\"le nombre des utilisateurs est :\"+ str(n_users) + \" Et le nombre des items est: \"+ str(n_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Un des problèmes qu'on a rencontré était le fait que les ids des items n'était pas ordonnée.\n",
    "\n",
    "C'est à dire on peut trouver l'utilisateur 1,2,3,5 et 8 sans trouver les utilisateurs 4 ,6 et 7. \n",
    "\n",
    "Ceci nous a posé un problème dans la création de la matrice user-item parce que on risque d'avoir plusieurs lignes et colonnes vides.\n",
    "\n",
    "Pour ça, on a crée un tableau indice_user et un tableau indice_item qui contiennent les anciens id et les nouvelles id \n",
    "par expl (1,2,5,6)=>(1,2,3,4) puis on a ajouté deux colonnes sur le tableau principale qui contient ces nouveaux IDs.\n",
    "\n",
    "(ps) ce traitement est très couteux, pour cela on l'a lancé une seule fois, on a exporté les nouvelles ids dans un fichier csv, et à chaque fois on utilise ce nouveau fichier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indice_user = pd.DataFrame()\n",
    "indice_user[\"indice\"]=range(1,len(useri)+1)\n",
    "indice_user[\"useri\"]=useri\n",
    "\n",
    "\n",
    "indice_item = pd.DataFrame()\n",
    "indice_item[\"indice\"]=range(1,len(itemi)+1)\n",
    "indice_item[\"itemi\"]=itemi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#créer user_ID_new et Item_ID_new\n",
    "x=[]\n",
    "y=[]\n",
    "for i in range(0,len(tab)):\n",
    "    x.append((indice_user.indice[indice_user.useri==tab.userId[i]].axes[0]+1)[0])\n",
    "    y.append((indice_item.indice[indice_item.itemi==tab.movieId[i]].axes[0]+1)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tab[\"userIdnew\"]=x\n",
    "tab[\"movieIdnew\"]=y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>userIdnew</th>\n",
       "      <th>movieIdnew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "      <td>1</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "      <td>1</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "      <td>1</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "      <td>1</td>\n",
       "      <td>932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1263</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759151</td>\n",
       "      <td>1</td>\n",
       "      <td>1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759187</td>\n",
       "      <td>1</td>\n",
       "      <td>1042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1293</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759148</td>\n",
       "      <td>1</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1339</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1260759125</td>\n",
       "      <td>1</td>\n",
       "      <td>1084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1343</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759131</td>\n",
       "      <td>1</td>\n",
       "      <td>1088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1371</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759135</td>\n",
       "      <td>1</td>\n",
       "      <td>1112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1260759203</td>\n",
       "      <td>1</td>\n",
       "      <td>1141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1953</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759191</td>\n",
       "      <td>1</td>\n",
       "      <td>1516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2105</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759139</td>\n",
       "      <td>1</td>\n",
       "      <td>1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2150</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759194</td>\n",
       "      <td>1</td>\n",
       "      <td>1709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2193</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759198</td>\n",
       "      <td>1</td>\n",
       "      <td>1744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759108</td>\n",
       "      <td>1</td>\n",
       "      <td>1816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2455</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759113</td>\n",
       "      <td>1</td>\n",
       "      <td>1963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2968</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1260759200</td>\n",
       "      <td>1</td>\n",
       "      <td>2381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>3671</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759117</td>\n",
       "      <td>1</td>\n",
       "      <td>2926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating   timestamp  userIdnew  movieIdnew\n",
       "0        1       31     2.5  1260759144          1          31\n",
       "1        1     1029     3.0  1260759179          1         834\n",
       "2        1     1061     3.0  1260759182          1         860\n",
       "3        1     1129     2.0  1260759185          1         907\n",
       "4        1     1172     4.0  1260759205          1         932\n",
       "5        1     1263     2.0  1260759151          1        1018\n",
       "6        1     1287     2.0  1260759187          1        1042\n",
       "7        1     1293     2.0  1260759148          1        1048\n",
       "8        1     1339     3.5  1260759125          1        1084\n",
       "9        1     1343     2.0  1260759131          1        1088\n",
       "10       1     1371     2.5  1260759135          1        1112\n",
       "11       1     1405     1.0  1260759203          1        1141\n",
       "12       1     1953     4.0  1260759191          1        1516\n",
       "13       1     2105     4.0  1260759139          1        1666\n",
       "14       1     2150     3.0  1260759194          1        1709\n",
       "15       1     2193     2.0  1260759198          1        1744\n",
       "16       1     2294     2.0  1260759108          1        1816\n",
       "17       1     2455     2.5  1260759113          1        1963\n",
       "18       1     2968     1.0  1260759200          1        2381\n",
       "19       1     3671     3.0  1260759117          1        2926"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tab.to_csv('ratings_new.csv')\n",
    "tab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#validation croisé:\n",
    "\n",
    "from sklearn import cross_validation as cv\n",
    "train_data, test_data = cv.train_test_split(tab[[\"userIdnew\",\"movieIdnew\",\"rating\"]], test_size=0.25,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "La régle dit que si on a une grande sparsity (ou bien rareté des données, c'est de ne pas arriver à calculer la \n",
    "similarité entre 2 utilisateurs par expl si chaqu'un a aimé different items que l'autre), les modèles Model Based seront les plus efficace.\n",
    "Calculant alors la sparsity:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparsity level of our data base is 98.4%\n"
     ]
    }
   ],
   "source": [
    "sparsity=round(1.0-len(tab)/float(n_users*n_items),3)\n",
    "print 'The sparsity level of our data base is ' +  str(sparsity*100) + '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "La pourcentage de sparsity est bien grande donc, on peut confirmer dés maintenant que les modèles Model Based seront les \n",
    "modèles les plus efficaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Memory based Collaboratif Filtering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 La mise en place du modèle:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "On va commencer par créer les modèles Memory based.\n",
    "\n",
    "    -Les modèles User-Based : \"Les utilisateurs qui sont similaires à vous, ont aimé aussi ...\"\n",
    "    \n",
    "    -Les modèles Item-Based: \"Les utilisateurs qui ont aimé ça, ont aimé aussi ...\"\n",
    "    \n",
    "Pour expliquer plus:\n",
    "\n",
    "-le modele User-Based: va prendre un utilisateur, trouve les utilisateur les plus similaires à lui en se basant sur la note, Puis recommande les items aimé par ces utilisateurs(ça prend un user et retourne des items)\n",
    "\n",
    "-Le modele Item-Based:prend un item, cherche les utilisateurs qui ont aimé cet item, trouve les items aimé par ces utilisateurs\n",
    "(ça prend un item et retounes une liste des items)\n",
    "\n",
    "Pour le faire, on utilisé 2 métriques le cosine similaire et cityblock.\n",
    "Pour le faire, on a commencé par créer les matrice user-item train et test. Ce sont les deux matrices qui vont croisé les notes de utilsiateurs et des items.\n",
    "Puis, on a créé nos 4 modèles Memory Based  \n",
    "à la fin, on a créé une fonction pour faire les prédictions selon le modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_data_matrix = np.zeros((n_users, n_items))#matrice nulle de longuer tous les users et tous les items\n",
    "for line in train_data.itertuples():#parcourire la ligne col par col\n",
    "    train_data_matrix[line[1]-1, line[2]-1] = line[3] \n",
    "\n",
    "test_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in test_data.itertuples():\n",
    "    test_data_matrix[line[1]-1, line[2]-1] = line[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calcule de la cos similarity : (construction du modèle)\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "user_similarity = pairwise_distances(train_data_matrix, metric='cosine')\n",
    "item_similarity = pairwise_distances(train_data_matrix.T, metric='cosine')\n",
    "user_similarity1 = pairwise_distances(train_data_matrix, metric='cityblock')\n",
    "item_similarity1 = pairwise_distances(train_data_matrix.T, metric='cityblock')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict(ratings, similarity, type='user'):#prend\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1)#mean pour chauqe utilisateur (type = float)\n",
    "        #np.newaxis pour convertir mean_user_rating de array de float en array d'array pour l'utiliser avec ratings\n",
    "        #puis on a normalisé la var ratings (rating - E)\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis]) #(type === array comme la var rating)\n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)]) \n",
    "        \n",
    "    x = np.zeros((n_users, n_items))\n",
    "    for i in range(0,n_items):\n",
    "        a=max(pred[:,i])\n",
    "        b=min(pred[:,i])\n",
    "        c=0\n",
    "        d=5\n",
    "        for j in range(0,n_users):\n",
    "            x[j,i]=(pred[:,i][j]-(a-c))*d/(b-a+c)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#la prédiction avec les differents modèles:\n",
    "item_prediction = predict(test_data_matrix, item_similarity, type='item')\n",
    "user_prediction = predict(test_data_matrix, user_similarity, type='user')\n",
    "item_prediction1 = predict(test_data_matrix, item_similarity1, type='item')\n",
    "user_prediction1 = predict(test_data_matrix, user_similarity1, type='user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. La comparaison des RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#la creation de la fonction qui calcule le RMSE:\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, ground_truth): #Root Mean Squared Error\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten() \n",
    "    #.flatten() fusionne les elts des array en un array\n",
    "    #on attribue a prediction, les résultats des prédictions où on connait le vrais rating cad:\n",
    "    #prediction: tous nos prédictions sur test; ground_truth.nonzero():les vrais résultats qu'on a dans test\n",
    "    #on va mettre dans prediction les valeurs qu'on a prédit pour les elts qu'on adéja.\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()#pareil dans ground truth\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF: The RMSE for the cosine similarity metric is : 1.4977638525\n",
      "Item-based CF: The RMSE for the cosine similarity metric is :  1.50327465213\n",
      "User-based CF: The RMSE for the cityblock similarity metric is :   1.5172654194\n",
      "Item-based CF: The RMSE for the cityblock similarity metric is : 1.55417757528\n"
     ]
    }
   ],
   "source": [
    "print 'User-based CF: The RMSE for the cosine similarity metric is : ' + str(rmse(user_prediction, test_data_matrix))\n",
    "print 'Item-based CF: The RMSE for the cosine similarity metric is :  ' + str(rmse(item_prediction, test_data_matrix))\n",
    "print 'User-based CF: The RMSE for the cityblock similarity metric is :   ' + str(rmse(user_prediction1, test_data_matrix))\n",
    "print 'Item-based CF: The RMSE for the cityblock similarity metric is : ' + str(rmse(item_prediction1, test_data_matrix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Le meilleur modèle est celui qui a le RMSE le plus petit.\n",
    "\n",
    "Pour notre cas c'était User based pour la métrique cosine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Conclusion: \n",
    "    \n",
    "-Les modèles Memory based sont  facile à implementer et génére des bonnes résultats.\n",
    "\n",
    "-Ce type de modèle n'est pas scalable (n'est pas vraiment pratique dans un problème d'une grande base de donnée vu qu'il \n",
    "calcule à chaque fois la corrélation entre tous les utilisateur &/| les items) et ne resolut pas le problème de cold start(\n",
    "lorsqu'on commence avec un nouveau utilisateur/item dont on n'a pas assez d'information)\n",
    "\n",
    "Pour répondre au problème de scalability on crée les modele Model Based(partie suivante).\n",
    "\n",
    "Pour répondre au problème de cold start, on utilise la recommandation Content based (on va pas l'utiliser vu qu'on n'a pas ces données )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Model-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Dans cette partie du projet, nous appliquons le deuxième sous-type du fitrage collaboratif : \"Model-based\". \n",
    "Il consiste à appliquer la matrice de factorisation (MF) : c'est une méthode d'apprentissage non supervisé de décomposition\n",
    "et de réduction de dimensionnalité pour les variables cachées. \n",
    "\n",
    "Le but de la matrice de factorisation est d'apprendre les préférences cachées des utilisateurs et les attributs cachés des items\n",
    "depuis les ratings connus dans notre jeu de données, pour enfin prédire les ratings inconnus en multipliant les matrices de varibales cachées des utilisateurs et des items. \n",
    "\n",
    "Il existe plusieurs techniques de réduction de dimensionnalité dans l'implémentation des systèmes de recommendations. \n",
    "\n",
    "Dans notre projet, nous avons utilisé :\n",
    "\n",
    "- SVD : singular value decomposition\n",
    "\n",
    "- SGD : Stochastic Gradient Descent\n",
    "\n",
    "- ALS \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Singular value decomposition (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 La mise en place des SVD:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Cette technique, comme toutes les autres, consiste à réduire la dimensionnalité de la matrice User-Item calculée précedemment.\n",
    "Posons R la matrice User-Item de taille m x n (m : nombre de users, n: nombre d'items) et  k: la dimension de l'espace des caractères cachés.\n",
    "L'équation générale de SVD est données par : R=USV^T avec:\n",
    "\n",
    "- La matrice U des caractères cachés pour les utilisateurs : de taille m*k\n",
    "\n",
    "- La matrice V des caractères cachés pour les items : de taille n*k\n",
    "\n",
    "- La matrice diagonale de taille k x k avec des valeurs réelles non-negatives sur la diagonale\n",
    "\n",
    "On peut faire la prédiction en appliquant la multiplication des 3 matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "#Obtenir les composantes de SVD à partir de la matrice User-Item du train. On choisit une valeur de k=20.\n",
    "u, s, vt = svds(train_data_matrix, k = 100)\n",
    "s_diag_matrix=np.diag(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Multiplication des 3 matrices avec np.dot pour obtenir la matrice User_Item estimée.\n",
    "X_pred = np.dot(np.dot(u, s_diag_matrix), vt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#la normalisation de X_pred vu qu'elle retourne des données qui sont pas bien distribué dans [0,5]\n",
    "import math\n",
    "x = np.zeros((n_users, n_items))\n",
    "for i in range(0,n_items):\n",
    "    a=max(X_pred[:,i])\n",
    "    b=min(X_pred[:,i])\n",
    "    c=0\n",
    "    d=5\n",
    "    for j in range(0,n_users):\n",
    "        x[j,i]=(X_pred[:,i][j]-(a-c))*d/(b-a+c)\n",
    "        if math.isnan(x[j,i]): x[j,i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.46997911037\n"
     ]
    }
   ],
   "source": [
    "# Calcul de performance avec RMSE entre la matrice estimée et la matrice du test\n",
    "print 'RMSE: ' + str(rmse(x, test_data_matrix))\n",
    "#On a trouvé 1.49 comme RMSE, c'est plus grand que le RMSE des modèles Memory based, mais ça prend énormement moins du temps.\n",
    "#Ce qu'on va dans la partie qui suit c'est d'améliorer notre modèle par le gradient stochastique et l'ALS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Stochastic Gradient Descent with Weighted Lambda Regularisation (SGD-WR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. La mise en place du modèle:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "********** Algorithme SGD (Stochastic Gradient Descent) ************\n",
    "\n",
    "Quand on utilise le filtrage collboratif pour SGD,on veut estimer 2 matrices P et Q: \n",
    "\n",
    "- La matrice P des caractères cachés pour les utilisateurs : de taille m*k (m: nombre d'utilisateurs, k: dimension de l'espace des caractères cachés)\n",
    "\n",
    "- La matrice Q des caractères cachés pour les items : de taille n*k (m: nombre d'items, k: dimension de l'espace des caractères cachés)\n",
    "\n",
    "Après l'estimation de P et Q, on peut alors prédire les ratings inconnus en multipliant les matrices P et la transposée de Q.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Les matrices I et I2 serviront de matrices de sélecteur pour prendre les éléments appropriés après la création du Train et du Test\n",
    "#selecteur de var est égal à 1 si la valeur dans la matrice est != 0\n",
    "\n",
    "# matrice d'indices pour le train\n",
    "I = train_data_matrix.copy()\n",
    "I[I > 0] = 1\n",
    "I[I == 0] = 0\n",
    "\n",
    "# matrice d'indices pour le test\n",
    "I2 = test_data_matrix.copy()\n",
    "I2[I2 > 0] = 1\n",
    "I2[I2 == 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# La fonction prediction permet de prédire les ratings inconnus en multipliant les matrices P et la transposée de Q\n",
    "def prediction(P,Q):\n",
    "    return np.dot(P.T,Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Pour mettre à jour P et Q, on peut utiliser le SGD où on itère chaque observation dans le train pour mettre à jour P et Q au fur et à mesure: \n",
    "\n",
    "Q_{i+1} = Q_i + (gamma) (e{ui}*P_u - (lambda)* Q_i)\n",
    "\n",
    "P_{i+1} = P_i + (gamma) (e{ui}*Q_u - (lambda)* P_i)\n",
    "\n",
    "On note: \n",
    "\n",
    "- (gamma) la vitesse de l'apprentissage\n",
    "\n",
    "- (lambda) le Terme de régularisation\n",
    "\n",
    "- e :l'erreur qui est la différence entre le rating réel et le rating prédit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ****** Initialisation ******* \n",
    "\n",
    "lmbda = 0.1 # Terme de régularisation\n",
    "k = 20 # dimension de l'espace des caractères cachés\n",
    "m, n = train_data_matrix.shape  # nombre d'utilisateurs et d'items\n",
    "steps = 150  # Nombre d'itération \n",
    "gamma=0.001  # vitesse d'apprentissage\n",
    "\n",
    "P = 3 * np.random.rand(k,m) # Matrice des caractères cachés pour les utilisateurs\n",
    "Q = 3 * np.random.rand(k,n) # Matrice des caractères cachés pour les items\n",
    "\n",
    "#les matrices P et Q sont initialisées avec des valeurs aléatoires au début, mais leur contenu change à chaque itération en se \n",
    "#basant sur le train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Il existe plusieurs métriques d'évaluation, mais la plus populaire des métriques utilisée pour évaluer l'exactitude des ratings prédits\n",
    "est l'erreur quadratique moyenne (RMSE) qu'on a utilisé dans notre projet :\n",
    "\n",
    "RMSE =RacineCarrée{(1/N) * sum (r_i -estimé{r_i})^2}\n",
    "\"\"\"\n",
    "\n",
    "def rmse2(I,R,Q,P):\n",
    "    return np.sqrt(np.sum((I * (R - prediction(P,Q)))**2)/len(R[R > 0]))\n",
    "\n",
    "#R = train_data_matrix\n",
    "#prediction(P,Q): estimateur du train_data_matrix avec la méthode de factorisation\n",
    "#I pour prendre seulement la partie significative de la matrice (!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#On ne considère que les valeurs !=0 \n",
    "users,items = train_data_matrix.nonzero()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#implémentation de the SGD-WR: (ps) cet algo prend du temps ça depend de nombre steps choisi.\n",
    "train_errors = [] #stocker les erreurs du train obtenus par RMSE à chaque itération (step) \n",
    "test_errors = [] #stocker les erreurs du test obtenus par RMSE à chaque itération (step) \n",
    "     \n",
    "for step in xrange(steps):\n",
    "    for u, i in zip(users,items): #zip() retourne les tuples (user,item)\n",
    "        e = train_data_matrix[u, i] - prediction(P[:,u],Q[:,i])  # calculer l'erreur e pour le gradient\n",
    "        P[:,u] += gamma * ( e * Q[:,i] - lmbda * P[:,u]) # mise à jour de la matrice P\n",
    "        Q[:,i] += gamma * ( e * P[:,u] - lmbda * Q[:,i])  # mise à jour de la matrice Q\n",
    "        \n",
    "    train_rmse = rmse2(I,train_data_matrix,Q,P) # Calcul de l'RMSE à partir du train\n",
    "    test_rmse = rmse2(I2,test_data_matrix,Q,P) # Calcul de l'RMSE à partir du test\n",
    "    train_errors.append(train_rmse) #à chaque itération ajouter l'erreur à la liste\n",
    "    test_errors.append(test_rmse) #à chaque itération ajouter l'erreur à la liste\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 1.50060377979\n"
     ]
    }
   ],
   "source": [
    "print 'RMSE : ' + str(np.mean(test_errors)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAGHCAYAAAAHoqCrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEIIkQgyFUIIIYRIBJkKIYQQQiTC/wKuTftqv1TudQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115a7828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Maitenant, après avoir obtenus toutes les valeurs de l'erreur à chaque étape,on peut tracer la courbe d'apprentissage.\n",
    "# ==> On Vérifie la performance en traçant les erreurs du train et du test\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(steps), train_errors, marker='o', label='Training Data'); \n",
    "plt.plot(range(steps), test_errors, marker='v', label='Test Data');\n",
    "plt.title('Courbe d apprentissage SGD')\n",
    "plt.xlabel('Nombre d etapes');\n",
    "plt.ylabel('RMSE');\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Le modèle semble fonctionner bien avec,relativement, une basse valeur de RMSE après convergence.\n",
    "La performance du modèle peut dépendre des paramètres (gamma), (lambda) et k qu'on a varié à plusieurs reprises afin d'obtenir \n",
    "le meilleur RMSE.\n",
    "\n",
    "Après cette étape, on peut comparer le rating réel avec le rating estimé; Pour ce faire, on utilise la matrice User-item qu'on a \n",
    "déjà calculée et utilisé la fonction prediction(P,Q) implémentée précédemment. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 ALS : Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Index matrix for training data\n",
    "I = train_data_matrix.copy()\n",
    "I[I > 0] = 1\n",
    "I[I == 0] = 0\n",
    "\n",
    "# Index matrix for test data\n",
    "I2 = test_data_matrix.copy()\n",
    "I2[I2 > 0] = 1\n",
    "I2[I2 == 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ps: on n'a pas commenté car c'est presque le mm principe que le modele SGD!\n",
    "lmbda = 0.1 \n",
    "k = 20 \n",
    "n_epochs = 2 # Nombre d'étapes\n",
    "m, n = train_data_matrix.shape # Number of users and items\n",
    "P = 3 * np.random.rand(k,m) # Latent user feature matrix\n",
    "Q = 3 * np.random.rand(k,n) # Latent item feature matrix\n",
    "Q[0,:] = train_data_matrix[train_data_matrix != 0].mean(axis=0) # Avg. rating for each movie\n",
    "E = np.eye(k) # (k x k)-dimensional idendity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/2] train error: 1.044781, test error: 1.369094\n",
      "[Epoch 2/2] train error: 0.764674, test error: 1.240162\n",
      "Algorithm converged\n"
     ]
    }
   ],
   "source": [
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "# Repeat until convergence\n",
    "for epoch in range(n_epochs):\n",
    "    # Fix Q and estimate P\n",
    "    for i, Ii in enumerate(I):\n",
    "        nui = np.count_nonzero(Ii) # Number of items user i has rated\n",
    "        if (nui == 0): nui = 1 # Be aware of zero counts!\n",
    "    \n",
    "        # Least squares solution\n",
    "        Ai = np.dot(Q, np.dot(np.diag(Ii), Q.T)) + lmbda * nui * E\n",
    "        Vi = np.dot(Q, np.dot(np.diag(Ii), train_data_matrix[i].T))\n",
    "        P[:,i] = np.linalg.solve(Ai,Vi)\n",
    "        \n",
    "    # Fix P and estimate Q\n",
    "    for j, Ij in enumerate(I.T):\n",
    "        nmj = np.count_nonzero(Ij) # Number of users that rated item j\n",
    "        if (nmj == 0): nmj = 1 # Be aware of zero counts!\n",
    "        \n",
    "        # Least squares solution\n",
    "        Aj = np.dot(P, np.dot(np.diag(Ij), P.T)) + lmbda * nmj * E\n",
    "        Vj = np.dot(P, np.dot(np.diag(Ij), train_data_matrix[:,j]))\n",
    "        Q[:,j] = np.linalg.solve(Aj,Vj)\n",
    "    \n",
    "    train_rmse = rmse2(I,train_data_matrix,Q,P)\n",
    "    test_rmse = rmse2(I2,test_data_matrix,Q,P)\n",
    "    train_errors.append(train_rmse)\n",
    "    test_errors.append(test_rmse)\n",
    "    \n",
    "    print \"[Epoch %d/%d] train error: %f, test error: %f\" \\\n",
    "    %(epoch+1, n_epochs, train_rmse, test_rmse)\n",
    "    \n",
    "print \"Algorithm converged\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Conclusion:\n",
    "Cet algorithme est le meilleur de tous les autres algorithmes. \n",
    "Dans 2 itération on a trouvé un erreur de train qui est égale à 1.0.764674 et un erreur de test qui est égale à 1.240162\n",
    "Comme c'est l'algorithme le plus rapide et le plus efficace, On a décidé de le généralisé sur tout le jeu de données.\n",
    "\"\"\"\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
